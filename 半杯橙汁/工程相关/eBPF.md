# BPF之巅

> 与其说是笔记，不如说是抄书，因为这个领域是完全陌生的，每一句话都需要仔细理解。

## 第一章 引言

### 1.1 BPF和eBPF是什么

简单来说，BPF提供了一种在各种内核事件和应用程序事件发生时运行一段小程序的机制（可以理解为钉子，钉在应用程序和内核事件之间）。

BPF由指令集、存储对象和辅助函数等几部分组成。由于它采用了虚拟指令集规范，因此也可将它视作一种虚拟机实现。这些指令由Linux内核的BPF运行时模块执行，具体来说，该运行时模块提供两种执行机制：一个解释器和一个将BPF指令动态转换为本地化指令的即时(JIT)编译器。在实际执行之前，BPF指令必须先通过验证器(verifer)的安全性检查，以确保BPF程序本身不会崩溃或者损坏内核。

扩展后的BPF(eBPF)，官方缩写依旧为BPF。实际上，在内核仍然只有一个执行引擎，即BPF，同时支持扩展后的BPF和“经典”的BPF

### 1.2 跟踪、嗅探、采样、剖析和可观测性都是什么

这些都是用来对分析技术和工具进行分类的术语

#### 跟踪(tracing)、嗅探

​	跟踪是基于事件的记录--这也是BPF工具所使用的监测方式。如Linux下的strace(1)，可以记录和打印系统调用事件的信息。也有像Linux中top(1)这种不跟踪事件，而是使用固定的计数器统计监测事件的频次，然后打印出摘要信息。一个**显著的特点**是，跟踪工具具备记录原始事件和事件元数据的能力。但是这类数据体量是庞大的，而BPF技术催生了可编程跟踪工具的出现，可以通过运行一段小程序来进行定制化的实时统计摘要或其他动作

​	常见工具有:strace,tcpdump以及Solaris系统中的各类嗅探器(snoop)

#### 采样(sampling)

​	通过获取全部观测量的子集来描绘目标的大致图像。也被称为profiling。有一个BPF工具就叫profile(8)，它基于计时器对运行中的代码进行定时采样。采样器的优点是，性能开销比跟踪工具小。缺点是，只提供了一个大致的图像，可能遗漏细节

#### 可观测性(observability)

​	通过全面观测来理解一个系统，可实现该目标的工具就可以归类为可观测性工具。包括跟踪、采样和基于固定计数器的工具。但是不包括基准测量(benchmark)工具，基准测量工具在系统上模拟业务负载，会更改系统的状态。BPF工具就属于可观测性工具，这些工具使用BPF技术进行可编程型跟踪分析。

> 总的来说，可观测性是跟踪采样的总体抽象

### 1.3 BCC、bpftrace和IO Visor

为了方便BPF程序的编写，在跟踪方面两个主流的前端：BCC和bpftrace

BCC（BPF编译器集合，BPF Compiler Collection）是最早用于开发BPF跟踪程序的高级框架。它提供了一个编写内核BPF程序的C语言环境，也为诸如Python、Lua和C++提供接口。也是libbcc和libbpf库的前身。这两个库提供了使用BPF程序对事件进行观测的库函数。BCC则是提供了70多个BPF工具。

bpftrace是一个新出现的前端，专门用于创建BPF工具的高级语言支持。bpftrace也是基于libbcc和libbpf库进行构建的

BCC和bpftrace的关系如图，bpftrace在编写功能强大的单行程序或者短小的脚步方面较强；BCC更适合开发复杂的脚本和作为后台进程使用，还可以调用其他的库支持(类比VS和vscode)：

![image-20240920144945199](./images/image-20240920144945199.png)

嵌入式方面有一个ply的BPF前端，较为轻量化且依赖最小化。部分bpftrace工具在转为ply语法后就可以使用ply执行，但是ply尚不成熟。

BCC和bpftrace都不在内核代码仓库中，均属于GitHub中名为IO Visor的Linux基金会项目

+ [ply](https://github.com/iovisor/ply)
+ [bpftrace](https://github.com/bpftrace/bpftrace)
+ [BCC](https://github.com/iovisor/bcc)

### 1.5 BPF跟踪的能见度

无需重启，当我们需要对内核组件、设备、应用库进行检查时，可以立即使用BPF工具对其现场直播

### 1.6 动态插桩：kprobes和uprobes

动态插桩技术：在生产环境对于正在运行的软件插入观测点的能力。在未启用时，软件不受任何影响，动态插桩开销为零。其中kprobes值得是内核函数插桩，uprobes是用户态函数插桩，在bpftrace中使用的动态插桩示例如下：

![image-20240920153840880](./images/image-20240920153840880.png)

### 1.7 静态插桩：tracepoint和USDT

>  tracepoint又称为内核跟踪点。

动态插桩技术有一大缺点：随着软件变更，被插桩的函数可能被重新命名，或者被移除。当内核或者应用软件升级后，BPF工具可能无法正常工作。这属于接口稳定性问题。并且在使用了编译器优化后，部分函数会被转换为内联函数(inline)函数，对于这些函数，就无法使用kprobes或者uprobes。

对于上述的问题，统一的解决方法是改用静态插桩技术。静态插桩会将稳定的事件名字编码到软件代码职工，由开发者进行维护。BPF工具支持内核的静态跟踪点插桩技术，也支持用户态的静态定义跟踪插桩技术USDT(user level statically defined tracing)。静态插桩技术的缺点显而易见，增加了开发者的维护成本，因此即使软件中存在静态插桩点，数量也十分有限。

上述缺点除非自己开发BPF工具，否则无需关注。如有需要，推荐先使用静态跟踪(跟踪点或者USDT)，不够用的话再使用动态插桩技术(kprobes或uprobes)。bpftrace中使用静态插桩技术的例子：

![image-20240920160047436](./images/image-20240920160047436.png)

### 1.8 初识bpftrace：跟踪open()

> 需要注意的是，当使用系统调用的跟踪点的时候，需要再内核编译的时候，打开`CONFIG_FTRACE_SYSCALLS`选项

使用bpftrace跟踪系统调用open(2)，可以使用一个现有的静态插桩点(syscall:sys_enter_open)，使用bpftrace可以写一个单行程序，在调用open的时候输出进程的名字和传递给open系统调用的文件名：

![image-20240920160848613](./images/image-20240920160848613.png)

其中bpftrace程序被定义在单引号内，编写后enter会立即编译执行，ctrl+c会结束同时移除BPF程序。也体现了BPF跟踪工具提供的按需插桩的工作方式：只在相关命令存活期间被激活。

open系统调用有很多的变体，可以通过命令选项`-l`使用统配符进行跟踪列出所有和open相关的跟踪点

![image-20240920161351459](./images/image-20240920161351459.png)

实际上，openat这个变体使用的频率可能更高，可以使用bpftrace来验证一下：

![image-20240920161511400](./images/image-20240920161511400.png)

上述的计算信息都是在内核态下高效计算出来的，当bpftrace定义的程序过长的时候，可以将其制作为一个脚本进行执行。

bpftrace提供了一个跟踪所有系统调用开始和结束位置的程序opensnoop.bt

![image-20240920162122721](./images/image-20240920162122721.png)

### 1.9 再回到BCC：追踪open()

BCC版本的opensnoop

![image-20240920162336293](./images/image-20240920162336293.png)

BCC提供的工具一般会提供更加复杂的功能：

![image-20240920162522759](./images/image-20240920162522759.png)

这也就体现了BCC和bpftrace的差异：BCC自带工具很多，可以直接上手使用；而bpftrace则语法简单，更适合定制化开发

## 第二章 技术背景

### 2.1 图释BPF

![image-20240920173010953](./images/image-20240920173010953.png)

### 2.2 BPF

BPF的工作方式：最终用户通过BPF虚拟机的指令集（也称为BPF字节码）定义过滤器表达式，然后传递给内核，有**解释器**执行。因此包过滤式在内核中直接执行的，避免了向用户态进程复制每个数据包。同时，BPF还提供了安全保障，用户自定义的过滤器首先需要通过安全性验证。tcpdump就使用了BPF过滤，其简要流程如下：

![image-20240920173645165](./images/image-20240920173645165.png)

使用tcpdump -d 参数可以打印出过滤器表达式的BPF指令：

![image-20240920173749734](./images/image-20240920173749734.png)

### 2.3 eBPF

Linux运行时各模块的架构如下图，该图展示了BPF指令如何通过BPF验证器验证，再有BPF虚拟机执行。BPF虚拟机包括一个解释器以及一个JIT(及时 just in time)编译器:JIT负责生成处理器可直接执行的机器指令。验证器则拒绝不安全的指令。![image-20240920174523589](./images/image-20240920174523589.png)

BPF可以通过辅助函数获取内核状态，利用BPF映射表进行存储。BPF程序在特定时间发生时执行，包括动态插桩（kprobes,uprobes）以及静态插桩(跟踪点)

#### 2.3.1 为什么性能工具需要BPF

BPF的与众不同之处在于，同时具备了高效率和生产环境安全性的特点，并且已经内置在了Linux内核中，有了BPF就可以直接使用BPF工具，无需新增内核组件。

#### 2.3.3 编写BPF程序

进行BPF编程的前端工具，从低级到高级排列如下：

+ LLVM：可以使用C语言或者LLVM中间表示形式(Intermediate Representation)进行编写，然后再编译为BPF，LLVM自带优化器，可以对它生成的BPF指令进行效率和体积上的优化
+ BCC：允许使用C语言编写BPF程序。内部实现仍然是使用LLVM中间表示形式和一个LLVM库来实现BPF编译
+ bpftrace：提供自己的高级语言。内部实现仍然是使用LLVM中间表示形式和一个LLVM库来实现BPF编译

虽然很少使用到直接通过BPF指令集进行编程的情况，但是在使用工具遇到问题的时候，会有查看指令的需求。接下来两个小节通过bpftool以及bpftrace进行示例

#### 2.3.4 使用BPF查看指令集：bpftool

Linux4.15添加了bpftool这个工具，可以用来查看和操作BPF对象，包括BPF程序和对应的映射表。源码位于Linux源码的tools/bpf/bpftool中

bpftools的默认输出展示了所操作的BPF对象：

![image-20240925085939087](./images/image-20240925085939087.png)

对于每一个对象，都有一个专门的帮助文档：

![image-20240925090049265](./images/image-20240925090049265.png)

**bpftools perf**显示了哪些BPF程序正在通过perf_event_open()进行挂载：

![image-20240925090246767](./images/image-20240925090246767.png)

![image-20240925090552353](./images/image-20240925090552353.png)![image-20240925090558677](./images/image-20240925090558677.png)

以上输出有3个不同的PID，分属不同的BPF程序

+ PID 1765 是Vecotr BPF PMDA大理，用来做实例性能分析(细节见17章)
+ PID 21993 是bpftrace版本的biolatency。它显示使用两个uprobes（用户态插桩）,即bpftrace中的BEGIN和END探针，还有两个kprobes(内核态插桩)用于对块IO的起始结束进行插桩（第9章有该程序的源码）
+ PID 25440 是BCC版本的biolatency，它正在对另一个块IO的起始函数进行插桩

offset字段显示了被插桩对象的偏移量。对于bpftrace，偏移量1781920匹配了bpftrace二进制文件中的BEGIN_trigger函数，偏移量1781927匹配了END_trigger函数(可以使用readelf -s bpftrace来进行验证)

prog_id是BPF程序ID，可以使用该命令进行打印：

```shell
bpftool prog show 
```

![image-20240925091428245](./images/image-20240925091428245.png)

输出以程序ID开始（262 263），示例中是BCC的kprobe程序，该程序中带有BTF(BPF Type Format)信息，这可以从上面的输出显示的btf_id看出来。此时仅需要知道BTF是BPF版本的调试信息就可以了。

bpftool prog dump xlated

每个BPF程序都可以通过它的ID被打印出来。xlated模式将BPF指令翻译为汇编指令打印出来。示例中为程序234、bpftrace块IO完成跟踪程序的输出：

![image-20240926085137293](./images/image-20240926085137293.png)![image-20240926085143213](./images/image-20240926085143213.png)

上述输出显示了可被BPF调用的受限的内核辅助函数之一：bpf_probe_read()

以下为比较上述输出（非黑体汇编）和观测块IO完成事件的程序（黑体）输出，该程序基于BTF编译，ID是263：

![image-20240926085522511](./images/image-20240926085522511.png)

如果程序中包含了BTF信息，那么可以使用linum修饰符在输出中增加源代码文件和行信息（使用黑体标记）

![image-20240926085728804](./images/image-20240926085728804.png)

使用opcodes可以输出包含BPF指令的opcode(黑体表示，操作码)：

![image-20240926090017965](./images/image-20240926090017965.png)

修饰符visual,可以以DOT格式输出控制流信息，支持使用外部可视化软件打开。以下例子使用的是GraphVix软件和其绘制有向图工具dot(1):

![image-20240926090219035](./images/image-20240926090219035.png)

以下为使用GraphVix中的osage对BPF程序可视化执行的结果：

![image-20240926090400653](./images/image-20240926090400653.png)

bpftool prog dump jited

prog dump jited子命令显示了经过JIT编译之后的机器码。示例为x86_64体系结构下BCC的块IO完成跟踪程序：

![image-20240926090641470](./images/image-20240926090641470.png)![image-20240926090649981](./images/image-20240926090649981.png)

bpftool btf

bpftool可以打印BTF的ID，如BTF ID 5 是BCC的块IO的完成事件的输出：

![image-20240926091136016](./images/image-20240926091136016.png)![image-20240926091143860](./images/image-20240926091143860.png)

#### 2.3.5 使用bpftrace查看BPF指令集

tcpdump 的-d参数可以输出BPF指令，bpftrace也可以通过-v/-d参数达到该效果：

![image-20240926091516099](./images/image-20240926091516099.png)

大多数人不是设计到BPF指令层次的修改或者错误排查，这些事情应该交给社区来管理，大咖也可以直接向社区提供补丁

#### 2.3.6 BPF API

**BPF辅助函数**

BPF不允许任意调用内核函数，内核为BPF提供了可以调用的辅助函数，以下为部分辅助函数：

![image-20240926180027805](./images/image-20240926180027805.png)![image-20240926180037270](./images/image-20240926180037270.png)

辅助函数中的“current”是指的是当前正在运行的线程，也就是当前正在CPU上执行任务的线程。

在内核源文件的头文件中，一般会为函数提供注释，而Linux的源码文件可以从一些网站上浏览

**bpf_probe_read()**

bpf_probe_read()是一个十分重要的函数。BPF中内存访问权限仅限于BPF寄存器和栈空间以及通过辅助函数访问的BPF映射表。如果需要访问其他内存（如BPF之外的其他内核地址），就必须通过bpf_probe_read()来读取。

该函数会进行安全性检查并禁止缺页中断的发生，以保证在probe上下文中不会发生缺页中断。

此外，该函数还可以将用户空间的内容读取到内核空间。

**BPF系统调用命令**

部分系统调用：

![image-20240927090701521](./images/image-20240927090701521.png)

其中第一列可以作为bpf系统调用的第一个参数进行传递，使用strace(1)可以看到。如下例可以看到BCC版本的execsnoop(8)工具用到了那些bpf(2)系统调用：

![image-20240927090957974](./images/image-20240927090957974.png)![image-20240927091010505](./images/image-20240927091010505.png)

这里需要**注意**，应该避免直接使用strace，因为当前的ptrace()实现会严重降低目标进程的运行速度----->性能下降为不足原来的%1。这里使用仅仅是因为他已经支持bpf(2)系统调用的参数翻译，即将一个数字翻译为一个可读的字符串

**BPF程序类型**

不同的BPF程序类型定义了BPF程序可以挂载的事件类型，以及事件的参数。主要用于跟踪用途的BPF程序类型如下：

![image-20240927091728222](./images/image-20240927091728222.png)

在bpf.h中还有一些程序类型用于网络以及其他用途，如下：

![image-20240927091829753](./images/image-20240927091829753.png)

**BPF映射表类型**

定义了不同类型的映射表数据结构：

![image-20240927092001965](./images/image-20240927092001965.png)

#### 2.3.7 BPF并发控制

在Linux5.1 增加辅助函数spin lock之前，BPF还不支持并发控制。

术语丢失的更新：在进行跟踪的时候，并行的多个线程可能会同时对映射表数据进行查找和更新，造成一个线程破坏另一个线程的数据，即由当前的读和写发生了重叠造成的（本质上还是数据竞态）

跟踪程序使用的BCC和bpftrace前端，使用了per-CPU的哈希和数组映射类型，以尽可能的避免冲突。他们为每个*逻辑*CPU创建了独享的数据结构实例，避免了并行的线程对共享的位置进行更新。例如，一个对事件进行计数的映射表，可以通过对每个CPU上的映射表数据结构进行更新，然后再将每个CPU对应的映射表中的值相加，以得到事件总数。

具体的例子，对单行bpftrace程序使用per-CPU哈希映射来计数：

![image-20240927093210725](./images/image-20240927093210725.png)

而该单行bpftrace程序使用了普通的哈希映射来计数：

![image-20240927093252978](./images/image-20240927093252978.png)![image-20240927093303638](./images/image-20240927093303638.png)

如果在一个8-CPU系统上同时运行这两个程序，结果如下：

![image-20240927093353545](./images/image-20240927093353545.png)

可以看到，普通的哈希映射大概会丢掉0.01%的统计值

除了每个CPU专用的映射之外，还有其他一些机制进行并发控制，包括互斥的相加操作（BPF_XADD）、“映射中的映射”机制（可以对整个映射进行原子更新的操作），以及BPF的自旋锁等机制。使用bpf_map_update_elem()对常规的哈希和LRU映射进行操作也是原子性的，不会产生写竞争。在Linux5.1中引入的自旋锁，可以通过bpf_spin_lock()和bpf_spin_unlock()进行控制。

#### 2.3.8 BPF sysfs接口

在Linux4.4中，可以将BPF程序和BPF映射通过虚拟文件系统显露出来，位置通常位于/sys/fs/bpf。术语为“钉住”(pinning)。

该机制允许创建持续运行的BPF程序（像daemon程序那样），即使创建程序进程已经退出，程序仍然可以运行。该机制还提供了用户态程序和正在运行的BPF程序交互的另一种方式：用户态程序可以读取和修改BPF映射表。

#### 2.3.9 BPF类型格式(BTF BPF Type Format)

BTF(BPF Type Format)是一个元数据的格式，用来将BPF程序的源代码信息编码到调试信息中。调试信息包括BPF程序、映射结构等很多其他信息。BTF包含函数的信息，源代码/行信息，以及全局变量信息等。

BTF调试信息可以内嵌到vmlinux二进制文件中，或者随BPF程序一桶使用原生Clang编译生成，或通过LLVM JIT生成。这样BPF程序就更容易被加载器（eg. libbpf）或者工具(eg. bpftool)所使用。检测和跟踪工具，包括bpftool(8)和perf(1)，可以获取这些信息，以得到源代码标记的BPF程序，或者可以基于它们的C结构表示美观地打印映射表的键值，而不需要使用裸十六进制形式打印。

除了描述BPF程序外，BTF正在成为一个通用的、用来描述所有内核数据结构的格式。

BPF跟踪工具通常需要在机器上安装内核头文件（一般是通过linux-headers包），这样才可以访问各种C结构。

有时候这些头文件没有包含全部的内核结构定义，对有些BPF追踪工具来说比较困难：临时的解决方法是，在BPF工具中重新定义这些结构体。有时候，过于复杂的头文件无法被正确处理，bpftrace遇到这种情况会选择直接终止。BTF可以通过提供对所有数据结构的准确定义来解决这些问题。在未来，一个带着BTF信息的Linux啮合vmlinux二进制文件，将会是自描述的（这句话云里雾里的，理解不了）。

#### 2.3.10 BPF CO-RE

CO-RE(Compile Once - Run Everywhere)，即一次编译，到处运行。皆在将BPF程序一次性编译为字节码，然后其他机器执行的时候就不再需要安装BPF编译器，这对嵌入式系统尤为重要。

#### 2.3.11 BPF的局限性

BPF程序不能随意调用内核函数；只能调用在API中定义的BPF辅助函数。BPF程序在执行循环时也有限制：允许BPF将一个无限循环插入kprobes是不安全的，因为这些线程可能持有重要的锁，从而导致整个系统的死锁。解决方法包括循环展开，以及在使用循环的通用场景添加特定的辅助函数等。Linux5.3内核支持BPF受限循环，该循环的上限可以通过验证器验证。

BPF栈的大小设定不能超过MAX_BPF_STACK，值为512。当遇到空间不足的时候，解决方法是使用BPF映射存储空间，映射存储空间是有大小限制的。在bpftrace项目中，已经开始了将字符串的存储位置从栈空间转移到映射的工作。

Linux5.2内核以后，无需考虑BPF程序的总指令数量。但是在之前的内核，BPF程序的总指令数量限制为4096.

#### 2.3.12 BPF扩展阅读资料

+ 内核代码：Documentation/networking/filter.txt
+ 内核代码：Documentation/bpf/bpf_design_QA.txt
+ bpf(2) man 
+ bpf-helper(7) man
+ 《BPF:the universal in-kernel virtual machine》，作者Jonathan Corbet
+ 《BPF internals-II》，作者为Suchakra Sharma
+ Cilium项目的"BPF and XDP Reference Guide"

### 2.4 调用栈回溯

BPF提供了存储调用栈信息的专用映射表数据结构，可以保存基于帧指针或基于ORC的调用栈回溯信息。

#### 2.4.1 基于帧指针的调用栈回溯

帧指针技术依赖的是以下*惯例*：函数调用栈帧链表的头部，始终保存于某个寄存器中（在x86_64中，这个寄存器是RBP），并且函数调用的返回地址永远位于RBP的值指向的位置加上一个固定偏移量（+8）。这意味着任何调试器或者跟踪器都可以在中断程序执行后，通过读取RBP后遍历以RBP的值为头部的链表，同时在固定位置返回地址，从而轻松的进行栈回溯，过程如图：

![image-20240927154050674](./images/image-20240927154050674.png)

AMD64 ABI中提到，RBP作为帧指针寄存器来使用是一种惯用做法，而非强制要求。为了节省函数前言(prologue)和结语(epilogue)的指令数量，也可以不将RBP用作帧指针寄存器，而是将其作为通用寄存器来使用。

目前，gcc编译器默认不启用函数帧指针，而将RBP作为通用寄存器来使用，这样就无法基于帧指针进行栈回溯。但是可以通过gcc的命令行参数-fno-omit-frame-pointer来改变这个默认行为。至于为什么不开启，一个是为了针对寄存器较少的机器进行性能提升，另一个是为了商业竞争（和Intel的icc比拼）

在x86_64中，这种优化提升的性能不足百分之一，甚至没有什么可观察提升。所以开启帧指针从而支持CPU剖析得到的性能优化提升潜力，远远超过了启用帧指针带来的小小的性能损失。

当然，帧指针并非进行栈回溯的唯一方法，还可以使用调试信息(debuginfo)、LBR以及ORC

#### 2.4.2 调试信息

软件的额外调试信息以软件的调试信息包(debuginfo package)的形式提供，这其中包含了DWARF格式的ELF调试信息。该调试信息中包含了供gdb(1)这样的调试器来做调用栈的文件段信息，这样即使没有启用帧指针寄存器也可以进行栈回溯。ELF中的调试相关文件是.eh_frame和.debug_frame

调试信息文件中的某些段也包含程序的源代码和行号信息，这就导致文件的调试信息远远大于被调试的原始二进制文件的尺寸，这也是为什么调试信息文件被称为DWARF的原因。

BPF目前还不支持这种栈回溯技术，因为太耗费处理器资源，而且需要读取可能并没有加载到内存中的ELF段信息。这使得在禁用中断的受限BPF上下文实现相关支持几乎不可能。

不过BCC和bpftrace是支持使用调试信息文件进行符号解析的

#### 2.4.3 最后分支记录LBR

最后分支记录(Last Brance Record,LBR)是Intel处理器的一项特性：程序分支，包含函数调用分支信息，被记录在硬件缓冲区中。该技术没有额外开销，可以用来进行调用栈重组。但是支持记录的深度有限制，根据型号不同，可记录分支数量在4-32个之间。

目前BPF并不支持LBR

#### 2.4.4 ORC

> 命名的故事：ORC（兽人）的提出是针对之前DWARF（矮人）提案的回应，而DWARF也和ELF（精灵）文件格式呼应

针对栈回溯需求专门设计了一种新的调试信息格式---Oops回滚能力（Oops Rewind Capability，ORC）。相比DWARF格式，该格式对处理器要求较低。ORC使用名为.orc_unwind和.orc_unwind_ip的ELF文件段，目前Linux内核已经实现了相关支持。在寄存器受限的体系结构上，可能会存在不开启帧指针的情况下编译内核，然后使用ORC技术进行栈回溯。

在内核中基于ORC的调用栈回溯可以通过perf_callchain_kernel()函数支持，BPF可以调用该函数，这意味着BPF也支持基于ORC的调用栈。目前还没有开发用户态对ORC调用栈的支持。

#### 2.4.5 符号

调用栈信息目前在内核中是以地址数组形式记录的，这些地址可以通过用户态的程序翻译为符号（如函数的名字[实例](https://panthema.net/2008/0901-stacktrace-demangled/)）。在收集和翻译两个操作之间，符号映射表可能发生变化，这会导致翻译无效或有些符号信息丢失。

### 2.5 火焰图

火焰图可以用来可视化来自任何剖析器或者跟踪所记录的调用栈信息

#### 2.5.1 调用栈信息

调用栈信息，也称为栈回溯跟踪或调用跟踪信息，是一串展示了代码流向的函数信息。其信息显示中，底部为起点（栈），顶部则是当前函数

#### 2.5.2 对调用栈信息的剖析

以定时采样方式收集调用栈信息，一般会收集很多信息。为了易于分析，Linux的perf(1)剖析器将其样本摘要为调用树格式，显示每个分支所占的百分比。BCC的profile(8)则是对每个独特的调用栈分别计数。如果有某个调用栈占用大部分的CPU运行时间，这两种工具可以很快识别出来。但是对于许多其他的分析场景，包括一些微小的新能回归测试，定位问题可能需要研究大量的剖析器输出。火焰图就是为了解决这个问题。

CPU剖析器简单输出示例：

![image-20241008173413282](./images/image-20241008173413282.png)

其中，a->b->c这条代码路径调用了7次（c正在CPU上运行），a->b路径调用了2次（b正在CPU上运行），a->b->d->e调用了一次（e正在CPU上运行）

#### 2.5.3 火焰图

上述示例对应的火焰图则如下：

![image-20241008173603953](./images/image-20241008173603953.png)

可以看到火焰图的特点：

+ 每个方块代表了调用栈中的一个函数
+ Y轴表示了栈深度，即栈帧的数量。其顺序依旧是栈的形式，顶部代表叶子，底部代表根。
+ X轴包括了全部的采样样本的数量。方块的长度代表该函数在剖析文件中出现次数的比重。

火焰图实际上是一个反转的冰柱布局图，这种布局图可以用于对一组栈的调用关系进行可视化。每个垂直方向，出现在顶部的函数就是正在CPU上运行的函数。

从上图可以看出，c函数在CPU上占据了大概70%左右的时间，b为20%，c为10%，剩下的函数则没有直接的运行采样。

### 2.6 事件源

部分可跟踪的事件源以及在Linux内核中的BPF绑定点：

![image-20241008175010957](./images/image-20241008175010957.png)

### 2.7 kprobes

kprobes可以对任何内核函数进行插桩，还可以对函数内部的指令进行插桩。它可以实时在生产环境系统重启用，无需重启系统亦或者内核。

kprobes技术还有另外一个接口，即kretprobes，用来对内核函数返回时进行插桩以获取返回值。当用kprobes和kretprobes对同一个函数进行插桩时，可以使用时间戳来记录函数执行的时长。这是**性能分析中的一个重要指标**

#### 2.7.1 kprobes是如何工作的

使用kprobes对内核函数进行插桩的过程如下：

+ 对于一个kprobe插桩来说(流程类似硬中断的处理)：

  > + 将要插桩的目标地址中的字节内容复制并保存---->为的是给单步断点指令腾出位置
  > + 以单步中断指令覆盖目标地址：在x86_64上是int3指令。如果kprobes开启了优化，则使用jmp指令。
  > + 当指令流执行到断点时，断点处理函数会检查这个断点是否是由kprobes注册的，如果是，就会执行kprobes处理函数。
  > + 原始指令继续执行，指令流继续
  > + 当不需要kprobes时，原始的字节内容会被复制回目标地址上，这样这些指令就回到了他们的初始状态。

+ 如果这个kprobe是一个Ftrace已经做过插桩的地址（一般位于函数入口处），那么可以基于Ftrace进行kprobe优化，过程如下：

  > + 将一个Ftrace kprobe处理函数注册为对应函数的Ftrace处理器
  > + 当在函数起始处执行内建入口函数时(x86架构上的gcc4.6是\_\_fentry\_\_)，该函数会调用Ftrace，Ftrace接下来会调用kprobe处理函数
  > + 当kprobe不再被使用的时候，从Ftrace中移除Ftrace-kprobe处理函数

+ 如果是一个kretprobe:

  > + 对函数入口进行kprobe插桩
  > + 当函数入口被kprobe命中时，将返回地址保存并替换为一个“蹦床”(trampoline)函数地址
  > + 当函数最终返回时(ret指令)，CPU将控制交给蹦床函数处理
  > + 在kretprobe处理完成之后再返回到之前保存的地址
  > + 当不再需要kretprobe时，函数入口的kprobe就被移除

根据当前系统结构的体系结构，kprobe的处理过程可能需要禁止抢占或者禁止中断。

kprobe已经做了十分安全的防范措施。实际使用中最大的风险是在使用一个执行频率特别高的函数进行插桩的时候，每次函数调用的开销都将增加，这会对性能造成影响。

kprobes在某些ARM 64位系统上不能正常工作，因为这些平台上的内核代码区不允许被修改。

#### 2.7.2 kprobes接口

最初使用kprobes技术时，需要先写一个内核模块，通常用C书写入口处理函数和返回函数，再通过调用register_kprobe()注册。接下来加载该内核模块，使用printk()输出定制化信息。计数后，在调用unregister_kproce()作为结束。

现在有以下三种接口可访问kprobes：

+ kprobe API:如register_kprobe()等
+ 基于Ftrace的，通过/sys/kernel/debug/tracing/kprobe_events:通过向这个文件写入字符创，可以配置开启和停止kprobes
+ perf_event_open():与perf(1)工具所使用的一样，进来BPF耿总工具也开始使用这些函数。Linux内核4.17中接入了相关支持

最主要的使用方法还是借助前端追踪器，包括perf(1)、SystemTap以及BPF追踪器，如BCC和bpftrace

#### 2.7.3 BPF和kprobes

kprobes向BCC的bpftrace提供了内核动态插桩的机制，在很多工具中都用到了该机制。相关接口如下：

+ BCC:attach_kprobe()和attach_kretprobe()，支持对函数的开始或某一偏移量位置进行插桩。kretprobes都是在函数返回处进行动态插桩
+ bpftrace:kprobe和kretprobe探针类型，只支持在函数入口位置插桩。kretprobes都是在函数返回处进行动态插桩

简单的BCC例子：vfsstat(8)工具对VFS接口中的一些关键调用进行了插桩，每秒打印的概要信息：

![image-20241009142812645](./images/image-20241009142812645.png)

可以在vfsstat源代码中查看kprobe跟踪了那些函数：

![image-20241009143651870](./images/image-20241009143651870.png)

另一个bpftrace的例子，该单行程序通过匹配"vfs_"开头的函数，统计所有VFS函数的调用次数：

![image-20241009143837344](./images/image-20241009143837344.png)

#### 2.7.4 关于kprobes的更多内容

参考：

![image-20241009143946528](./images/image-20241009143946528.png)

### 2.8 uprobes

uprobes提供了用户态程序的动态插桩。其utrace接口和kprobes接口十分相似。uprobes在Linux内核3.5以上进行支持

uprobes与kprobes类似，只是在用户态程序使用。uprobes可以在用户态程序的函数入口、特定偏移处以及函数返回处进行插桩

uprobes也是基于文件的，当一个可执行文件中的一个函数被追踪时，所有使用到这个文件的进程都会被插桩，包括那些尚未启动的进程。这样就可以全系统范围内跟踪系统库调用。

#### 2.8.1 uprobes是如何工作的

与kprobes类似：将一个快速断点指令插入目标指令处，该指令将执行转交给uprobes处理函数。当不再需要uprobes时，目标指令会恢复成原来的样子。对于uretprobes，也是在函数入口处使用uprobe进行插桩，而在函数返回之前，则使用一个蹦床函数对返回地址进行劫持，和kprobes类似。

可以通过调试器看到该行为。比如从bash(1)中反汇编readline()函数：

![image-20241009145404453](./images/image-20241009145404453.png)

而使用了uprobes(或者uretprobes)进行插桩：

![image-20241009145442005](./images/image-20241009145442005.png)

注意，第一个指令已经被替换成int3单步中断。

可以使用一个bpftrace单行程序来对readline()进行插桩：

```shell
bpftrace -e 'uprobe:/bin/bash:readline { @ = count() }'
```

该程序对当前正在运行以及后续会运行的bash shell的readline()进行跟踪。打印出统计计数，使用`Ctrl+C`退出。当bpftrace停止运行时，uprobe会被移除，原始的指令被恢复回去。

#### 2.8.2 uprobes接口

+ 基于Ftrace的，通过向`/sys/kernel/debug/tracing/uprobe_events`配置文件中写入特定字符串打开或关闭uprobes
+ perf_event_open():和perf(1)工具的用法一样。相关支持已经加入内核4.17版本。

在内核中同时包含了register_uprobe_event()函数，和register_kprobe()类似，但是没有以API形式显露

#### 2.8.3 BPF与uprobes

uprobes为BCC和bpftrace提供了用户态程序的动态插桩支持，这在多个工具中都有使用。接口如下：

+ BCC:attach_uprobe()和attch_uretprobe()
+ bpftrace:uprobe和uretprobe探针类型

同kprobe一样，BCC支持在函数入口，指定偏移量处，函数返回处进行插桩。而bpftrace仅支持入口和返回处进行插桩、

举个BCC中的例子:gethostlatency(8)工具利用对库函数getaddrinfo(3)和gethostbyname(3)的插桩对主机名解析(DNS)访问进行跟踪

![image-20241009163617240](./images/image-20241009163617240.png)

被跟踪的函数可以通过源代码看到：

![image-20241009163646486](./images/image-20241009163646486.png)

bpftrace的例子，该单行程序列出并统计了libc系统库中gethost函数的调用次数：

```shell
bpftrace -l 'uprobe:/lib/x86_64-linux-gnu/libc.so.6:gethost*'
```

![image-20241009163912034](./images/image-20241009163912034.png)

```shell
bpftrace -e 'uprobe:/lib/x86_64-linux-gnu/libc.so.6:gethost* { @[probe] = count(); }'
```

![image-20241009164001463](./images/image-20241009164001463.png)

#### 2.8.4 uprobes的开销和未来的工作

uprobes可能会被挂载到高频事件上，比如malloc()和free()。此时可能会导致应用程序10倍以上的性能损耗。所以只能应用于测试环境中的故障排查过程。

目前正在讨论使用共享库来替换目前的、需要往返内核的uprobes实现，这样可以使BPF跟踪完全在用户态内进行。该技术已经被LTTng-UST使用了几年了，性能比当前实现相比快10-100倍

#### 2.8.5 扩展阅读

![image-20241009164357299](./images/image-20241009164357299.png)

### 2.9 跟踪点(tracepoints)

跟踪点可以用来对内核进行静态插桩。内核开发正在内核函数特定逻辑位置处，有意放置了这些插桩点；这些跟踪点会被编译到内核的二进制文件中。在Linux内核2.6.32开始支持。kprobes和跟踪点比较：

![image-20241009164833795](./images/image-20241009164833795.png)

对于内核开发者来说，跟踪点无疑增加了维护成本，并且其适用范围比kprobes要小很多。其有点是它的API比较稳定：即使内核升级了，大部分跟踪点依旧可以使用。但是kprobes的工具在内核版本升级时，如果被跟踪函数被重命名或者功能改变，则会导致不可用。

所以如果条件允许，应当先尝试使用跟踪点，再使用kprobes

跟踪点的格式为"子系统:事件名"(subsystem:eventname,如kmem:kmalloc)

格式的前半部分，不同跟踪工具有不同叫法：系统、子系统、类、提供商等。

#### 2.9.1 如何添加跟踪点

可以查看sched子系统中`sched:sched_process_exec`是如何被加入内核的

在内核源代码目录树`include/trace/events`下有跟踪点相关的头文件，以下是`sched.h`部分截取内容：![image-20241009172753725](./images/image-20241009172753725.png)

上述代码的信息也会在运行时通过/sys目录下的Ftrace框架显露出来，对于每一个跟踪点会有一个对应的格式文件，如：

```shell
cat /sys/kernel/debug/tracing/events/sched/sched_process_exec/format
```

![image-20241009173205809](./images/image-20241009173205809.png)

各种跟踪器使用此格式文件来裂解跟踪点上绑定的元数据信息。下面的例子是在内核源代码`fs/exec.c`中通过`trace_sched_process_exec()`调用的

![image-20241009173525453](./images/image-20241009173525453.png)

#### 2.9.2 跟踪点的工作原理

跟踪点处于不启动的状态时，性能开销要尽可能的小。Mathieu Desnoyers使用了一项叫做“静态跳转补丁”(static jump patching)的技术。该技术依赖一个编译选项，如下：

+ 在内核编译阶段会在跟踪点位置插入一条不做任何命令的指令。在x86_64架构上，这是一个5字节的nop指令。这个长度的选择是为了确保以后可以将其替换为一个5字节的jump指令

+ 在函数尾部插入一个跟踪点处理函数，也叫做蹦床函数（之所以叫这个名字，是因为在执行过程中函数会跳入，然后再跳出这个处理函数）。这个函数会便利一个存储跟踪点探针回调函数的数组。这样做会导致函数编译结果稍稍变大，有可能对指令缓存有一些小影响。

+ 在执行过程中，当某个跟踪器启用跟踪点时（该跟踪点可能已经被其他跟踪器所启用）：

  > + 在跟踪点回调函数数组中插入一条新的跟踪器回调函数，以RCU（Read-copy update，允许在更新的同时读取数据）形式进行同步更新
  > + 如果之前跟踪点处于禁用状态，nop指令的地址会重写为跳转到蹦床函数的指令

+ 当跟踪器禁用某个跟踪点时：

  > + 在跟踪点回调函数数组中删除该跟踪器的回调函数，并以RCU形式进行同步更新
  > + 如果最后一个回调函数也被去除了，那么jmp指令再重写为nop指令。

这样可以最小化处于禁用状态的跟踪点的性能开销，几乎可以忽略不计。

如果asm goto指令不可用，那么将不再用jmp来替换nop，改为使用一个从内存中读取一个变量的状态分支。

#### 2.9.3 跟踪点的接口

跟踪点有以下两个接口：

+ 基于Ftrace的接口，通过`/sys/kernel/debug/tracing/events`：每个跟踪点的系统有一个子目录，每个跟踪点则对应目录下的一个文件（通过向这些文件中写入内容开启或关闭跟踪点）
+ perf_event_open():这是perf(1)工具一直以来用的接口，进来BPF追踪也开始使用。（通过perf_tracepoint PMU）

#### 2.9.4 跟踪点和BPF

跟踪点为BCC和bpftrace提供了内核的静态插桩支持。接口如下：

+ BCC:TRACEPOINT_PROBE()
+ bpftrace:跟踪点探针类型

Linux在4.7后BPF才支持跟踪点，所以工具相对较少

BCC中使用跟踪点的一个例子是tcplife(8).该工具为每个TCP会话打印一行摘要信息(第10章详细叙述)：

![image-20241011153946577](./images/image-20241011153946577.png)

作为bpftrace使用跟踪点的例子，下面单行程序会对之前的sched:sched_process_exec进行插桩：

![image-20241011154902446](./images/image-20241011154902446.png)

#### 2.9.5 BPF原始追踪点

Alexei Starovoitov开发了一个新的跟踪点接口：BPF_RAW_TRACEPOINT,在2018加入Linux4.17。它向跟踪点显露原始参数，这样可以避免因为需要创建稳定的跟踪点参数而导致的开销，因为这些参数可能压根没必要。这有点像以kprobes方式使用跟踪点：最终得到了一个不稳定的API，但是可以访问更多字段，也不需要承担跟踪点的性能损失。该方式相比kprobes更加稳定，因为跟踪点探针的名字是稳定的，不稳定的是参数。

Alexei的压测结果证明了BPF_RAW_TRACEPOINT性能好于kprobes和标准跟踪点：

![image-20241011155452816](./images/image-20241011155452816.png)

#### 2.9.6 扩展阅读

![image-20241011155524398](./images/image-20241011155524398.png)

### 2.10 USDT

用户态预定义静态跟踪(user-level statically defined tracing,USDT)提供了一个用户空间版的跟踪点机制。

USDT和用户态软件的日志或者跟踪相关技术的不同在于，它依赖于外部的系统跟踪器来唤起。如果没有外部跟踪器，应用中的USDT不会做任何事，也不会开启。

许多应用默认不开启USDT，显示开启需要使用配置参数--enable-dtrace-probes或者--with-dtrace

#### 2.10.1 添加USDT探针

有两种方式给应用程序添加USDT探针：通过systemtap-sdt-dev包提供的头文件和工具，或者使用自定义的头文件。这些探针定义了可以被放置在代码中各个逻辑位置上的宏，以此生成USDT的探针。BCC项目中的examples/usdt_sample目录下包含了USDT示例。这个例子可以用systemtap-sdt-dev头文件，或者使用Facebook的FollyC++库。

**Folly**

使用Folly添加USDT探针的过程如下

+ 在目标代码中增加头文件：

  ```c++
  #include "folly/tracing/StaticTracepoint.h"
  ```

+ 在目标位置增加USDT探针，采用如下格式：

  ```c++
  FOLLY_SDT(provider,name,arg1,arg2,...)
  ```

  "provider"对探针进行分类，"name"是探针的名字，后面是可选的参数。在BCC的USDT代码中包含了：

  ```c++
  FOLLY_SDT(usdt_sample_lib1,operation_start,operationId,request_input().c_str());
  ```

  这定义了一个usdt_sample_lib1:operation_start探针，带有两个参数。USDT例子中包含了operation_end探针。

+ 编译软件。可以使用readelf(1)工具来确认USDT探针是否存在：

  ![image-20241012091259569](./images/image-20241012091259569.png)

  readelf(1)的命令行参数-n打印了notes文件段（即文件注释信息，版本、构建时间、二进制程序接口等），这里显示了编译进去的USDT探针的信息。

+ 可选步骤：有时准备添加的参数，在探针的位置处没有现成的，必须使用耗费CPU的函数调用来构建。为了在这些探针未被使用时避免调用，可以在函数外面增加一个探针信号量：

  ```c++
  FOLLY_SDT_DEFINE_SEMAPHORE(provider,name)
  ```

  此时探针就变成了：

  ```c++
  if(FOLLY_SDT_IS_ENABLED(provider,name)){
      ...expensive argument processing...
      FOLLY_SDT_WITH_SEMAPHORE(provider,name,arg1,arg2,...);
  }
  ```

  这样昂贵的参数处理，只会在探针启用（激活）后才会发生。这个信号量地址可以通过readelf(1)查看，跟踪工具可以在探针启用的时候对它进行设定。

  注意：当信号量所保护的探针在使用时，这些跟踪工具通常需要指定一个PID，这样才可以设定该PID的信号量。

#### 2.10.2 USDT是如何工作的

当编译应用程序时，在USDT探针的地址放置一个nop指令。在插桩时，这个地址会由内核使用uprobes动态地将其修改为一个断点指令。

前面readelf(1)的输出中，探针的位置是0x6a2（？没找到？）。这是二进制段的偏移量，所以必须首先知道二进制段的起始位置在哪。如果采用了位置无关代码(PIE)技术，这项技术能够提高*地址空间排布随机化*(ASLR)的效果，那么这个值可能是变化的。

![image-20241012162125020](./images/image-20241012162125020.png)

起始地址是0x55a75372a000。打印出起始位置加探针的偏移量(0x6a2)

![image-20241012162230850](./images/image-20241012162230850.png)

将USDT探针激活后：

![image-20241012162254235](./images/image-20241012162254235.png)![image-20241012162300482](./images/image-20241012162300482.png)

nop指令被修改为int3(x86_64上的断点指令)。当该断点被触发时，内核会执行相应的BPF程序，其中带有USDT探针的参数。当USDT探针被禁用后，nop指令会被替换回来。

#### 2.10.3 BPF与USDT

USDT为BCC和bpftrace提供了用户态的静态探针支持，接口如下：

+ BCC：USDT().enable_probe()
+ bpftrace:USDT探针类型

比如，对前一个例子（在哪？没找到啊，这写的云里雾里的）中的循环探针进行观测：

![image-20241012162643585](./images/image-20241012162643585.png)

这个bpftrace单行程序也打印了传递给探针的整数参数。

#### 2.10.4 USDT的更多信息

![image-20241012162821528](./images/image-20241012162821528.png)

### 2.11 动态USDT

前面介绍的USDT探针技术，是需要被添加到源代码并编译到最终的二进制文件中，在插桩点留下nop命令，在ELF notes段中存放元数据。但是有一些语言，如Jave/JVM，是在运行的时候解释或者编译的。动态USDT可以给Java代码增加插桩点。

JVM已经内置在C++代码中，并包含了许多USDT探针--比如对GC时间、类加载，以及其他高级行为。这些USDT探针会对JVM的函数进行插桩。但是USDT探针不能被添加到动态进行编译的Java代码中。USDT需要一个提前编译好的、带一个包含了探针描述的notes段的ELF文件，这对于以JIT方式编译的Java代码来说是不存在的。

动态USDT解决方案如下（简单说就是套娃）：

+ 预编译一个共享库，带着想要内置在函数中的USDT探针。这个共享库可以用C/C++语言编写，它其中有一个针对USDT探针的ELF notes区域。它可以像其他USDT探针一样被插桩。
+ 在需要时，使用dlopen(3)加载该动态库。
+ 针对目标语言增加对该共享库的调用。

### 2.12 性能监控计数器

性能监控计数器(Performance monitoring counter,PMC)还有一些其他名字，比如性能观测计数器(Performance instrumentation counter,PIC)、CPU性能计数器(CPU Performance Counter,CPC)、性能监控单元事件(performance monitoring unit event,PMU event)。这些名词都是同一个东西：处理器上的硬件可编程计数器。

PMC数量众多，Intel从中选择了7个作为“架构集合”，这些PMC会对一些核心功能提供全局预览。可以使用CPUID指令来确认这些“架构集”PMC是否存在于当前处理器中。下表列出该集合，可作为有用的PMC的例子：

![image-20241012170421569](./images/image-20241012170421569.png)

PMC是性能分析领域至关重要的资源。只有通过PMC才能测量CPU指令执行的效率、CPU缓存的命中率、内存/数据互联和设备总线的利用率，以及阻塞的指令周期等。在性能分析方面使用这些方法可以进行各种细微的性能优化。

尽管有数百个可用的PMC，但任一时刻在CPU中只允许固定数量的寄存器（可能只有6个）进行读取。在实现中，需要选择通过这6个寄存器来读取哪些PMC，或者可以采用循环采样的方式覆盖多个PMC集合（Linux中的perf(1)工具可以自动支持这种循环采样）。其他软件类计数器则没有这种限制。

#### 2.12.1 PMC模式

PMC可以工作在以下两种模式中：

+ **计数**：在该模式下，PMC能够跟踪事件发生的频率。只要内核有需要，就可以随时读取，如每秒获取1次。这种模式开销几乎为0
+ **溢出采样**：在该模式下，PMC在所监控的事件发生到一定次数时通知内核，这样内核可以获取额外的状态。监控的事件可能会以每秒百万、亿级别的频率发生，如果每次事件都进行终端，会导致系统性能下降到不可用。解决方案就是利用一个可编程的计数器进行采样，具体来说，是当计数器溢出时，就向内核发信号。（比如，每10000次LLC缓存未命中事件，或者每100万次阻塞的指令始终周期）

采样模式对BPF跟踪来说更值得关注，因为它产生的事件给BPF程序提供了执行的时机。BCC和bpftrace都支持PMC事件跟踪。

#### 2.12.2 PEBS

由于存在中断延迟（俗称“打滑”）或者乱序执行，溢出采样可能不能正确地记录触发事件发生时的指令指针。对于CPU周期性能分析来说，打滑无关紧要，而且有些性能分析器会故意在采样周期中引入一些微小的不规则形，避免过锁步采样(lockstep sampling)（或者使用一个自带偏移量的采样频率，如99Hz）。但是对于测量如LLC的未命中率等，这样的采样指令就必须是精确的。

Intel开发了一种解决发难，叫精确事件采样（precise event-based sampling,PEBS）。PEBS使用硬件缓冲区来记录PMC事件发生时正确的指令指针。Linux的perf_events框架机制支持PEBS。

#### 2.12.3 云计算

许多云计算环境不提供对虚拟机上的PMC访问请求。这在技术上是有可能开启它的，如，Xen虚拟化内核中提供了vpmu命令行选项，可以支持将不同的PMC显露给客体机器。Amazon公司也对其Nitro虚拟化主机开启了许多PMC支持。

### 2.13 perf_events

perf_events是perf(1)命令所依赖的采样和跟踪机制，在Linux内核2.6.31版本并入。现在，BPF跟踪工具可以调用perf_events来使用它的特性。BCC和bpftrace先使用perf_events作为它们的环形缓冲区，然后又增加了对PMC的支持，现在又通过perf_event_open()来对所有的事件进行观测。

在BPF跟踪工具使用perf(1)的时候，perf(1)也开发了一个使用BPF的接口，这就让perf(1)成为有一个BPF跟踪器。与BCC和bpftrace不同，perf(1)的代码位于Linux内核代码树中，因此，perf(1)也是唯一内置在Linux中的BPF前端

### 2.14 小结

BPF性能工具用到了很多技术，包括：扩展板BPF，内核态和用户态下的动态插桩技术（kprobes和uprobes），内核态和用户态的静态跟踪技术(跟踪点和用户态标记)，以及perf_events第。BPF可以使用基于帧指针和ORC技术的调用栈回溯技术来获取调用栈，并可以通过火焰图进行可视化呈现。

## 第三章 性能分析

### 3.1 概览

#### 3.1.1 目标

一般来说，性能优化最终目标是改进最终用户的体验以及降低运行成本。通常可以测量的指标包括如下几项：

+ 延迟：多久可以完成一次请求或者操作，通常以毫秒为单位
+ 速率：每秒操作或请求的速率
+ 吞吐量：通常指每秒传输的数据量，单位bit/byte
+ 利用率：以百分比形式表示的某资源在一段时间内的繁忙程度
+ 成本：开销/性能比例

针对延迟的改进可以通过分析请求时间的组成，将其细分为各个组成部分，如，CPU上运行代码的时间；等待某个资源，如磁盘IO、网络以及锁的时间；还有等待CPU调度的时间等。可以自己编写BPF工具，直接跟踪应用的总体请求延迟以及各个部分的单独开销。但是这样的工具往往和具体应用相关，并且由于同时对多个事件进行跟踪会带来显著的运行开销。实践中，往往通过小而专的工具来研究特定组件的时间开销和延迟。

降低运行成本需要观测软硬件资源是如何被利用的，以及从中定位可优化的部分。这可能也会涉及对不同组件的使用情况进行日志记录和汇总统计，而非分析它们的时间开销和响应延迟。本书对这两种目标，都提供了对应的工具。

#### 3.1.2 分析工作

BPF性能分析工具，不只用于分析特定类型的问题。下表所示是一个性能分析工作的列表，以及在每项工作中BPF工具可以发挥的作用：

![image-20241015084849572](./images/image-20241015084849572.png)![image-20241015084901782](./images/image-20241015084901782.png)

#### 3.1.3 多重性能问题

在使用本书介绍的工具时，要做好同时发现多个性能问题的准备。此时主要问题将变成为识别出哪个性能问题才是最重要的。

### 3.2 性能分析方法论

方法论是一个可以遵循的过程：它知道从哪里开始，中间步骤有哪些和到哪里结束。《性能之巅：洞悉系统、企业与云计算》中叙述了十几种性能分析方法论。这里会简要介绍一下作为参考

#### 3.2.1 业务负载画像

业务负载画像的目的是理解实际运行的业务负载。无需对最终结果进行分析，不如系统延迟收到多少影响。“消除不必要的工作”是作者在性能优化结果中收益最显著的一种，通过研究业务负载的构成就可以找到这样的优化点。

开展业务负载画像的推荐步骤如下：

+ 负载是谁产生的（如，进程ID、用户ID、进程名、IP地址）？
+ 负载为什么会产生（代码路径、调用栈、火焰图）？
+ 负载的组成是什么（IOPS、吞吐量、负载类型）？
+ 负载怎样随着时间发生变化（比较每个周期的摘要信息）？

本书提供的很多工具可以回答上述问题。比如使用vfsstat(8),实机输出以及书籍输出:

![image-20241015090211104](./images/image-20241015090211104.png)

![image-20241015090234726](./images/image-20241015090234726.png)

这些输出就显示了虚拟文件系统(virtual file system,VFS)层名业务负载的细节，并回答了第3个问题（负载的组成是什么），即负载类型和操作的速率，同时还通过周期性输出回答了问题4（负载怎样随着时间发生变化）

作为第一个问题的例子，使用bpftrace运行一个单行程序(Ctrl+C后结束统计)：

![image-20241015091452575](./images/image-20241015091452575.png)![image-20241015091940977](./images/image-20241015091940977.png)

> 个人总结：就是系统某个方面的总体概况

#### 3.2.2 下钻分析

下钻分析的工作过程是从一个指标开始，然后将这个指标拆分成多个组成部分，再将最大的组件进一步拆分为更小的组件，不断重复这个过程知道定位出一个或多个根因。

下钻分析推荐步骤：

+ 从业务最高层开始分析
+ 检查下一个层级的细节
+ 挑出最感兴趣的部分或者线索
+ 如果问题没解决，跳至第二步

下钻分析可能会涉及对工具进行定制，此时bpftrace比BCC更加合适

举一个分析延迟的例子：

+ 请求延迟为100ms
+ 有10ms在CPU上运行，90ms消耗在脱离CPU的等待过程
+ 在脱离CPU等待的部分中，有89ms阻塞在文件系统上
+ 文件系统的部分，有3ms阻塞于锁上，而86ms阻塞于存储设备上

此时就可以确认存储设备是问题所在。另一个文件系统的例子：

+ 一个应用花费了89ms被阻塞在文件系统上
+ 文件系统花费了78ms被阻塞在写操作上，11ms被阻塞在读操作上
+ 在文件系统的写操作中，77mx没阻塞在时间戳的更新上

此时可以得出结论：文件系统访问时间戳是延迟的根源，它们可以被禁止（通过改变挂载选项）。这比“买个更快的磁盘”要好很多。

> 个人总结：找到感兴趣的大方向，再逐步分解，直到发现问题

#### 3.2.3 USE方法论

该方法为作者开发，具体步骤为针对每一个资源，分别去检查：

+ 使用率(usage)
+ 饱和度(saturability)
+ 错误(error)

使用本方法前的第一步是要找出或者绘制一幅软件和硬件资源图，然后一次针对所有资源检查上述3个指标。下图演示一个通用系统中的资源示例图：

![image-20241016090720845](./images/image-20241016090720845.png)

这个方法论的优势之一是，它以重要问题作为开始，而非以某种指标形式的答案作为开始，然后倒退它为什么重要。

#### 3.2.4 检查清单法

性能分析检查清单可以列出一系列工具和指标，用于对照运行和检查。这些工具和指标可以聚焦于那些唾手可得的性能问题：列出十几个常见的问题，以及对应的分析方法，这样每个人都能参照检查。

接下来会列出两个清单：

+ 使用了传统(非BPF)工具，比较适合于快速分析(开始的60秒)
+ 适合及早使用的BCC工具列表

### 3.3 Linux 60秒分析

以下清单适用于任何性能问题的分析工作，在分析性能问题的最初60秒内通常会进行的操作。

```shell
$ uptime
$ dmesg | tail
$ vmstat 1
$ mpstat -P ALL 1
$ pidstat 1
$ iostat -xz 1
$ free -m
$ sar -n DEV 1
$ sar -n TCP,ETCP 1
$ top
```

接下来会以此介绍每个工具，这些工具可以利用现成的资源快速定位可能的性能问题。即便不能，也可以提供一些线索，帮助后续使用BPF工具进行进一步定位。（橙子注：这个其实就是上一节所有方法论的第一步，都是在总体上概览系统概况）

#### 3.3.1 uptime

书籍：

![image-20241016091942311](./images/image-20241016091942311.png)

这个工具可以快速检查平均负载，也就是多少个任务（进程）需要执行。在Linux系统中，这些数字包含了想要在CPU上运行的进程，同时也包含了阻塞在不可中断（通常是磁盘I/O）上的进程。这给出了一个高层次视角的资源负载（或者说是资源需求），在此之后可以通过其他工具进行进一步检查。

> 橙子注：CPU负载情况定义在特定时间间隔内**运行队列中**的进程数量的平均值，简言之就是正在使用以及等待使用CPU(这里包含IO进程)的平均任务数。（注意区分和CPU使用率的区别）

三个数字分别是指数衰减的1min/5min/15min分钟滑动窗口累计值。

负载平均值应该首先检查，以确认性能问题是否还存在。如果一个较高的15分钟负载与一个较低的1分钟负载同时出现，可能意味着已经错过了问题发生的现场。

#### 3.3.2 dmesg | tail

书籍：![image-20241016093448228](./images/image-20241016093448228.png)

该命令显示过去10条系统日志。这里可以找寻可能的性能问题错误。书籍实例中显示了内存不足引发OOM和TCP的丢弃请求的记录。TCP相关日志可以指引下一步分析方向：查看SNMP计数器值(Check SNMP counters)。

#### 3.3.3 vmstat 1

书籍：

![image-20241016093942272](./images/image-20241016093942272.png)

参数`1`表示每隔一秒打印一次摘要信息；需要检查的列包括如下几个：

+ r：CPU正在执行和等待执行的进程数量。相比平均负载，该指标不包含IO，因此可以更好的排查CPU饱和度：一个比CPU数量多的r值代表CPU资源处于饱和状态。
+ free:空闲内存，单位是KB。如果数字位数一眼看不过来，那内存应该就够用。使用3.3.7节介绍的free -m命令，可以更好的解释空闲内存。
+ si和so：页换入和换出。如果这些值不为0，那么意味着系统内存紧张。该值仅在配置开启了交换分区后才会起作用。
+ us、sy、id、wa和st：这些都是CPU运行时间的进一步细分，是对所有CPU取平均之后的结果。它们分别代表用户态时间(user)、内核事件（系统态事件,system）、空闲(idle)、等待IO(wait)、以及被窃取事件(stolen time，指虚拟化环境下，别其他客户机所挤占的事件；或者是Xen环境下客户机自身隔离的驱动域运行时间)

书中实例显示CPU时间主要花在用户态，这就指引我们下一步将主要针对用户态代码进行剖析

#### 3.3.4 mpstat -P ALL 1

书籍：

![image-20241017090108014](./images/image-20241017090108014.png)

该命令将每个CPU分解到各个状态下的时间打印出来。书中示例暴露出一个问题：CPU0的用户态占用率高达100%，这是单个线程遇到瓶颈的特征。

对于较高%iowait时间也要注意，可以使用磁盘IO工具进一步分析；如果出现较高的%sys值，可以使用系统调用(syscall)跟踪和内核跟踪，以及CPU剖析等手段进一步分析。

#### 3.3.5 pidstat 1

书籍：

![image-20241017090459621](./images/image-20241017090459621.png)

pidstat(1)命令按每个进程展示CPU的使用情况。top(1)命令虽然也很流行，但是pidstat(1)默认支持滚动打印输出，这样可以采集到不同时间段的数据变化。书中示例显示了一个Java进程每秒使用的CPU资源在变化，这个百分比是对全部CPU相加的和(同top)

#### 3.3.6 iostat -xz 1

书籍：

![image-20241017090809099](./images/image-20241017090809099.png)![image-20241017090945551](./images/image-20241017090945551.png)

该命令显示了存储设备的IO指标，要检查的列包括如下几个：

+ r/s、w/s、rkB/s和wkB/s:这些是每秒向设备发送的读、写次数，以及读、写字节数。可以用这些指标对业务负载画像。某些性能问题仅仅是因为超过了能够承受的最大负载导致的。
+ await:IO的平均响应时间，以毫秒为单位。这是应用需要承受的事件，它同时包含了IO队列时间和服务时间。超过预期的平均响应时间，可看作设备已饱和或者设备层面有问题的表征。
+ avgqu-sz:设备请求队列的平均长度。比1大的值有可能是发生饱和的表征（不过对有些设备，尤其是对基于多块磁盘的虚拟设备来说，通常以并行方式处理请求）。
+ %util:设备使用率。这是设备繁忙程度的百分比，显示了每秒设备开展实际工作的时间占比。但它展示的并不是容量规划意义下的使用率，因为设备可以并行处理请求。大于60%的值通常会导致性能变差（可以通过await字段确认）。

示例中的输出项md0虚拟设备的写入负载约为300MB/s,看起来md0背后是两块nvme设备。

#### 3.3.7 free -m

![image-20241017092103202](./images/image-20241017092103202.png)

该输出显示了用MB作为单位的可用内存。检查可用内存(available)是否接近0；这个值显示了在系统中还有多少实际剩余内存可用，包括缓冲区和页缓存区。将一些内存用于缓存可以提升文件系统的性能。

#### 3.3.8 sar -n DEV 1

![image-20241017092310628](./images/image-20241017092310628.png)

将不同的指标进行组合，sar(1)工具具有不同的运行模式。该例中，作者使用它来查看网络设备指标。通过接口吞吐量信息rxKB/s和txKB/s来检查是否有指标达到了上限。

#### 3.3.9 sar -n TCP,ETCP 1

![image-20241017092605857](./images/image-20241017092605857.png)

现在使用sar(1)工具来查看TCP指标和TCP错误信息。相关字段解释：

+ active/s:每秒本地发起TCP连接的数量(通过调用connect()创建)
+ passive/s:每秒远端发起TCP连接的数量(通过调用accept()创建)
+ retrans/s:每秒TCP重传的数量

主动和被动连接计数对于业务负载画像很有用。重传则是网络或者远端主机有问题的征兆。

#### 3.3.10 top

![image-20241017092848946](./images/image-20241017092848946.png)

可以使用top命令作为结束，对相关结果进行二次确认，能够浏览系统和进程的摘要信息。

### 3.4 BCC工具检查

作者提供了一个通用的使用BCC工具的检查清单，位于BCC仓库的docs/tutorial.md文件中（橙子注：unbuntu安装后所有BCC工具为了和系统自带的工具冲突，都会加上后缀`-bpfcc`，如`execsnoop-bpfcc`）：

+ execsnoop
+ opensnoop
+ ext4slower（或者brtfs\*、xfs\*、zfs\*）
+ biolatency
+ biosnoop
+ cachestat
+ tcpconnect
+ tcpaccept
+ tcpretrans
+ runqlata
+ profile

以上工具对于创建新进程、打开文件、文件系统延迟、磁盘IO延迟、文件系统缓存性能、TCP新建连接与重传、调度延迟，以及CPU使用情况，提供了更多信息。

#### 3.4.1 execsnoop

![image-20241017144656103](./images/image-20241017144656103.png)

execsnoop(8)通过跟踪每次execve(2)系统调用，为每个新创建的进程打印一行信息。存活周期短的进程会消耗CPU资源，通过传统的周期执行的监控工具较难发现，可以使用execsnoop(8)来检查。具体细节将在第六章介绍。

#### 3.4.2 opensnoop

![image-20241017145134460](./images/image-20241017145134460.png)

opensnoop(8)在每次open(2)系统调用（及其变体）时打印一行信息，包括打开文件的路径、打开操作是否成功("ERR"列)。打开的文件可以透露应用程序工作的很多信息：识别应用程序的数据文件、配置文件和日志文件。有时候应用程序反复尝试打开一个不存在的文件时，会导致表现或者性能受损。opensnoop(8)会在第八章进一步介绍。

#### 3.4.3 ext4slower

![image-20241017145701891](./images/image-20241017145701891.png)

ext4slower(8)跟踪ext4文件系统中的常见操作（读、写、打开和同步），并且可以把耗时超过某个阈值的操作打印出来。这可以定位或者排除一类性能问题：应用程序正在通过文件系统等待某个较慢的磁盘IO。ext4之外的其他系统也有对应的工具：btrfsslower(8)、xfsslower(8)，以及zfsslowner(8)。第八章将进行更详细的介绍

#### 3.4.4 biolatency

![image-20241017150457552](./images/image-20241017150457552.png)

biolatency(8)跟踪磁盘IO延迟（即从向设备发出请求到请求完成的时间），并且以直方图显示。该形式比iostat(1)工具输出的平均值更好地解释磁盘IO性能。可以显示IO请求的多峰分布。示例中有多个峰位，分别位于0-1区间，8-15区间。离群点也很明显，在512-1023区间。第九章会详细介绍biolatency(8)。

#### 3.4.5 biosnoop

![image-20241017153826954](./images/image-20241017153826954.png)

biosnoop(8)将每一次磁盘IO请求打印出来，包含延迟之类的细节信息。第九章会借一步介绍biosnoop(8)

#### 3.4.6 cachestat

![image-20241018090346675](./images/image-20241018090346675.png)

cachestat(8)每秒(可指定时长)打印一行摘要信息，展示文件系统缓存的统计信息。可以使用这个工具发现缓存命中率较低的问题。第八章会进一步介绍cachestat(8)。

#### 3.4.7 tcpconnect

![image-20241018090625192](./images/image-20241018090625192.png)

tcpconnect(8)会在每次TCP连接建立(eg,通过connect()调用)时，打印一行信息，包含原地址、目的地址。第十章会详细介绍tcpconnect(8)。

#### 3.4.8 tcpaccept

![image-20241018090828108](./images/image-20241018090828108.png)![image-20241018090904707](./images/image-20241018090904707.png)

tcpaccept(8)每当有别动的TCP连接建立时，就会打印一行信息，同样包含源地址和目的地址。第十章会详细介绍tcpaccept(8)。

#### 3.4.9 tcpretrans

![image-20241018091033112](./images/image-20241018091033112.png)

每次TCP重传数据包时，tcpretrans(8)会打印一行记录，包含源地址和目的地址，以及当时该TCP连接所处的内核状态。

TCP重传会导致延迟和吞吐量方面的问题。如果重传发生在TCP ESTABLISHED状态下，会进一步寻找外部网络可能存在的问题。如果重传发生在SYN_SENT状态下，这可能是CPU饱和的一个征兆，也可能是内核丢包引发的。第十章会进一步介绍tcpretrans(8)

#### 3.4.10 runqlat

![image-20241018091318957](./images/image-20241018091318957.png)![image-20241018091324659](./images/image-20241018091324659.png)

runqlat(8)对线程等待CPU运行的时间进行统计，并打印一个直方图。这可以定位超出预期的CPU等待时间，就原因来说他可能是CPU饱和、配置错误或者调度问题引起的。第六章会进一步介绍runqlat(8)。

#### 3.4.11 profile

![image-20241018091523478](./images/image-20241018091523478.png)

profile(8)是一个CPU剖析器，该工具可以用来理解哪些代码路径消耗了CPU资源。它周期性地对调用栈进行采样，然后将消重后的调用栈连同出现的次数一起打印出来。第六章会详细介绍profile(8)。

## 第四章 BCC

BPF编译器集合(BPF Compiler Collection，简写为BCC，有时候也以小写形式出现，那时bcc是项目名字和软件包的名字)是一个开源项目，包含了用于构建BPF软件的编译器框架和库。是BPF的主要前端项目，别后有BPF开发者的支持，内核最新BPF跟踪特性通常会首先被应用在这里。

### 4.1 BCC的组件

BCC源代码文件目录结构如下：

![image-20241018092310052](./images/image-20241018092310052.png)

### 4.2 BCC的特性

#### 4.2.1 BCC的内核态特性

BCC会使用不少内核态的特性，如BPF、kprobes、uprobes等。下列清单的括号中包含了一些实现细节，这些在第二章介绍过：

+ 动态插桩，内核态（kprobes的BPF支持）
+ 动态插桩，用户态（uprobes的BPF支持）
+ 静态跟踪，内核态（跟踪点的BPF支持）
+ 时间采样事件（BPF，使用`perf_event_open()`）
+ PMC事件（BPF，使用`perf_event_open()`）
+ 过滤（使用BPF程序）
+ 调试打印输出（使用`bpf_trace_printk()`）
+ 基于每个事件的输出（使用`bpf_perf_event_open()`）
+ 基础变量（全局和每线程专属变量，通过BPF映射表实现）
+ 关联数组（associative array，通过BPF映射实现）
+ 频率统计（通过BPF映射表实现）
+ 直方图（支持以2的幂为区间，或线性以及自定义区间，通过BPF映射表实现）
+ 时间戳和时间差（通过`bpf_ktime_get_ns()`和BPF程序实现）
+ 调用栈信息，内核态（通过BPF stackmap实现）
+ 调用栈信息，用户态（通过BPF stackmap实现）
+ 可覆盖的环形缓冲区（通过`perf_event_attr.write_backward`实现）
+ 低成本开销的插桩支持（BPF JIT，以及在BPF映射表中进行统计）
+ 生产环境安全性（BPF验证器）

#### 4.2.2 BCC的用户态特性

BCC用户态前端和BCC代码仓库中提供了一下用户态的特性：

+ 静态跟踪，用户态（通过uprobes实现的SystemTap风格的USDT探针）
+ 调试打印输出（通过Python使用`BPF.trace_pipe()`和`BPF.trace_fields()`）
+ 基于每个事件的输出（BPF_PERF_OUTPUT宏和`BPF.open_perf_buffer()`）
+ 周期性输出（`BPF.get_table()`和`table.clear()`）
+ C结构体成员访问，内核态（将BCC重写器映射到`bpf_probe_read()`结果上）
+ 内核态的符号解析（`ksym()`和`ksymaddr()`）
+ 用户态的符号解析（`usymaddr()`）
+ 调试信息符号的解析支持
+ BPF跟踪点支持（TRACEPOINT_PROBE）
+ BPF调用栈回溯支持（BPF_STACK_TRACE）
+ 各种其他辅助宏和函数
+ 示例（在`/examples`目录下）
+ 工具（在`/tools`目录下）
+ 新手指引（在`/docs/tutorial*.md`中）
+ 参考手册（在`/docs/reference_guide.md`中）

### 4.3 安装BCC

可以查看BCC仓库中的INSTALL.md文件

#### 4.3.1 内核要求

主要的内核BPF组件都是在内核4.1到4.9版本之间发布的。推荐使用相对较新的内核版本

需要开启一下内核配置选项：CONFIG_BPF=y、CONFIG_BPF_SYSCALL=y、CONFIG_BPF_EVENTS=y、CONFIG_BPF_JIT=y以及CONFIG_HAVE_EBPF_JIT=y。一般情况下，在很多Linux发行版中是默认开启的，所以一般不需要自己进行变更。

### 4.4 BCC的工具

![image-20241018134942653](./images/image-20241018134942653.png)

![image-20241018135151306](./images/image-20241018135151306.png)

#### 4.4.1 重点工具

| 主题         | 重点工具                                                     | 章节 |
| ------------ | ------------------------------------------------------------ | ---- |
| 调试/多用途  | trace、argdist、funccount、stackcount、opensnoop             | 4    |
| CPU相关      | execsnoop、runqlat、runqlen、cpudist、profile、offcputime、syscount、softirq、hardirq | 6    |
| 内存相关     | memleak                                                      | 7    |
| 文件系统相关 | opensnoop、filelife、vfsstatt、fileslower、cachestat、writeback、dcstat、xfsslower、xfsdist、ext4dist | 8    |
| 磁盘IO相关   | biolatency、biosnoop、biotop、bitesize                       | 9    |
| 网络相关     | tcpconnect、tcpaccept、tcplife、tcpretrans                   | 10   |
| 安全相关     | capable                                                      | 11   |
| 编程语言相关 | javastat、javacalls、javathreads、javaflow、javagc           | 12   |
| 应用程序相关 | mysqld_qslower、signals、killsnoop                           | 13   |
| 内核相关     | wakeuptime、offwaketime                                      | 14   |

#### 4.4.2 工具的特点

BCC工具有以下共同特点：

+ 每一个都解决了实际的观测性问题，有其创建的必要性
+ 它们设计为在生产环境由root用户来使用
+ 每个工具都有一个对应的man帮助文档
+ 每个工具都配备了示例文件，其中有实力输出以及对输出的解释（在`tools/*_example.txt`文件中）
+ 很多工具都接收启动选项和参数，大部分工具在使用-h选项时会打印帮助信息。
+ 工具源代码以一段注释开始
+ 工具源代码遵循统一的风格（使用pep8工具进行统一检查）

为了保持风格的一致，新工具的加入需要由BCC维护者审阅，工具作者需要遵守BCC工具的开发指南:BCC CONTRIBUTING_SCRIPTS.md

尽管BCC支持不同的语言前端，但BCC工具中的用户态组件主要使用是Python语言，内核态BPF程序则主要使用C语言完成。

贡献者指南一条建议：“编写工具以解决特定问题，切勿贪多”。是在鼓励尽可能开发单一功能的工具，而非多用途的工具。（直接给我的大杂烩梦想干碎了）

#### 4.4.3 单一用途工具

UNIX哲学：专注做一件事，并把它做好(do one thing and do it well)。换一种说法是：创建小的高质量的工具，使用管道(pipe)将其连接起来以完成更复杂的任务。如grep(1)、cut(1)和sed(1)等。

BCC中单一功能工具：opensnoop(8)、execsnoop(8)和biolatency(8)。以opensnoop(8)为例，思考对于跟踪open(2)系列系统调用这个单一任务来讲，这些选项和输出可以如何组合：

![image-20241018153404088](./images/image-20241018153404088.png)![image-20241018153414879](./images/image-20241018153414879.png)

这些单一功能工具，相对来说易于维护以及新手友好。

#### 4.4.4 多用途工具

多用途工具优势：

+ 更好的可见性：不局限于分析单一的任务或者目标，而是可以同时观测多个不同组件
+ 减少代码重复：可以避免多个工具中存在相似的代码片段

在BCC中，最强大的多用途工具是funccount(8)、stackcount(8)、trace(8)以及argdist(8)。这些多用途工具通常需要用户来决定跟踪哪些事件。不过为了享受这些灵活性，用户需要知道使用了哪些kprobes、uprobes以及其他事件等细节。

### 4.5 funccount

funccount(8)的主要作用为：

+ 某个内核态或用户态函数是否被调用过
+ 该函数每秒被调用了多少次

出于运行效率考虑，funccount(8)在内核中使用一个BPF映射表数据结构维护事件的计数，这样它仅需将总数汇报该用户态。相比先将全部事件输出到用户态再进行处理的方式，该方式可以显著降低funccount(8)的开销。但是超高频的事件仍然可能导致不可忽略的额外开销。如，内存分配函数(`malloc()`、`free()`)如果使用funccount(8)进行跟踪，可能会造成高达30%的额外开销。第18章可以了解典型事件频率和对应的开销。

#### 4.5.1 funccount的示例

1.内核函数tcp_drop函数是否被调用：

![image-20241021090049689](./images/image-20241021090049689.png)

上述例子在开始到Ctrl+C之前，tcp_drop共调用了3次

2.内核中调用最频繁的虚拟文件系统(VFS)是那个

![image-20241021090209612](./images/image-20241021090209612.png)

可以看到，调用最频繁的是`vfs_write`函数

3.用户态的pthread_mutex_lock()**每秒**被调用的次数是多少？

![image-20241021090329020](./images/image-20241021090329020.png)![image-20241021090334926](./images/image-20241021090334926.png)

该函数对C函数库进行了插桩，针对范围是全系统的。

4.全系统内，libc库中调用最频繁的与字符串相关的函数是那个？

![image-20241021090547960](./images/image-20241021090547960.png)

5.执行最频繁的系统调用是那个？

![image-20241021090622398](./images/image-20241021090622398.png)![image-20241021090628005](./images/image-20241021090628005.png)

可是使用不同高度事件源回答。该例中，作者使用了syscalls系统中的跟踪点来匹配全部系统调用入口(`sys_enter_*`)。该例中，最频繁的系统调用是futex()

#### 4.5.2 funccount的语法

funccount(8)的命令行参数包括可以用来改变行为的选项，以及一个描述被插桩事件的字符串：

```shell
funccount [options] eventname
```

eventname的语法是：

+ `name`或者`p:name`：对内核函数`name()`进行插桩(p means probe?)
+ `lib:name` 或者 `p:lib:name`：对用户态lib库中的函数`name()`进行插桩
+ `path:name`：对位于path路径下文件中的用户态函数`name()`进行插桩
+ `t:system:name`：对名为`system:name`的内核跟踪点进行插桩(t means tracepoint?)
+ `u:lib:name`：对lib库中名为`name`的USDT探针进行插桩
+ `*`：通配符。`-r`选项允许使用正则表达式

funccount(8)在对内核和用户态函数进行插桩时，分别使用了kprobes和uprobes

#### 4.5.3 funccount的单行程序

对虚拟文件系统(VFS)内核函数进行计数：

```bash
funccount 'vfs_*'
```

对TCP内核函数进行计数：

```bash
funccount 'tcp_*'
```

统计每秒TCP发送函数的调用次数：

```bash
funccount -i 1 'tcp_send*'
```

展示每秒块IO事件的数量：

```bash
funccount -i 1 't:block:*'
```

展示每秒新创建的进程数量：

```bash
funccount -i t:sched:sched_process_fork
```

展示每秒libc中`getaddrinfo()`（域名解析）的调用次数：

```bash
funccount -i 1 c:getaddrinfo
```

对libgo中全部的`os.*`调用进行计数：

```bash
funccount 'go:os.*'
```

#### 4.5.4 funccount的帮助信息

```bash
funccount -h
```

### 4.6 stackcount

stackcount(8)对导致某事件发生的函数调用栈进行计数。和funccount(8)一样，事件源可以是内核态或者用户态函数、内核跟踪点或者USDT探针。主要作用为：

+ 某个事件为什么会被调用？调用的代码路径是什么？
+ 有哪些不同的代码路径会调用该事件，调用频次如何？

出于对性能的考虑，stackcount(8)在内核中使用一种特殊的、调用栈信息专用的BPF映射表结构进行统计。用户空间读取调用栈ID和统计数字，然后从BPF映射表中取出调用栈信息，在进行符号翻译和打印输出。和funccount(8)一样，工具的开销取决于被插桩事件的发生频率，且预期该工具开销会比funccount(8)高，毕竟需要调用栈回溯以及记录。

#### 4.6.1 stackcount的示例

假如在空闲系统上使用funccount(8)时，发现ktime_get()这个内核函数执行频率很高，达到了每秒8k次。该函数是读取系统时间的，为什么空闲的系统需要如此高的频率读取时间？

下例为使用stackcount(8)来定位导致ktime_get()调用的代码路径：

![image-20241022085707071](./images/image-20241022085707071.png)

实际的输出较长，这里做了截断。在每个调用栈中，一行信息对应一个函数，然后是该调用栈的次数。

使用-P选项可以让调用栈包含进程的名字和PID：

![image-20241022085857278](./images/image-20241022085857278.png)![image-20241022085902417](./images/image-20241022085902417.png)

进程PID为0，名称为“swapper/2”

#### 4.6.2 stachcount的火焰图

最初的火焰图软件将调用栈作为输入，一行对应一个调用栈，帧（函数名）直降使用分号进行分隔，每行的结尾是一个空格和计数。stackcount(8)可以使用-f选项生成这种格式。

下例会对ktime_get()持续跟踪10秒(-D 10)，区分每个进程(-P)，并生成一张火焰图：

```shell
# stackcount -f -P -D 10 ktime_get > out.stackcount01.txt
$ wc out.stackcount01.txt
1586	3425 387761 out.stackcount01.txt
$ git clone http://github.com/brendangregg/FlameGraph
$ cd FlameGraph
$ ./flamegraph.p1 --hash --bgcolors=grey < ../out.stackcout01.txt > out.stackcount01.svg
```

这里使用的工具wc(1)来显示输出的总行数1586——也就是有这么多不同调用栈和进程名字的组合。下图显示了最后生成SVG文件的截屏：

![image-20241022090649729](./images/image-20241022090649729.png)

该图显示了，大部分ktime_get()函数调用来自8个空闲线程——每个线程对应一个CPU，直观看起来它们拥有相似的调用“塔”。火焰图左侧那些比较窄的“塔”中还有一些其他来源。

#### 4.6.3 stackcount残缺的调用栈

在第2、第12和18章中会对调用栈以及其在实际使用中会遇到的问题进行讨论。调用栈信息不完整和符号缺失是常见的问题。

作为例子，先前调用栈中显示tick_nohz_idle_enter()调用了ktime_get()，然而这并没有在源代码中出现。代码中倒是有一个对idle_nohz_start_idle()的调用，其定义如下(kernel/time/tick-sched.c)：

![image-20241022091947977](./images/image-20241022091947977.png)

代码行数很短，可能被编译器内联了，所以就导致抓取到的栈调用关系显示了父函数直接调用了ktime_get()。在/proc/kallsysms文件中没有tick_nohz_start_idle这个符号，进一步印证它被内联了。

#### 4.6.4 stackcount的语法

stackcount(8)的参数定义了被插桩的函数：

```shell
stackcount [option] eventname
```

eventname的语法和funccount(8)一致。

+ `name`或者`p:name`：对内核函数`name()`进行插桩(p means probe?)
+ `lib:name` 或者 `p:lib:name`：对用户态lib库中的函数`name()`进行插桩
+ `path:name`：对位于path路径下文件中的用户态函数`name()`进行插桩
+ `t:system:name`：对名为`system:name`的内核跟踪点进行插桩(t means tracepoint?)
+ `u:lib:name`：对lib库中名为`name`的USDT探针进行插桩
+ `*`：通配符。`-r`选项允许使用正则表达式

#### 4.6.5 stackcount的单行程序

对创建块IO的函数调用栈进行计数：

```shell
stackcount t:block:block_rq_insert
```

对发送IP数据包的调用栈进行计数：

```shell
stackcount ip_output
```

对发送IP数据包的调用栈进行计数，同时显示对应的PID：

```shell
stackcount -P ip_output
```

对导致线程阻塞并且导致脱离CPU的调用栈进行计数：

```shell
stackcount t:sched:sched_switch
```

对导致系统调用read()的调用栈进行计数：

```shell
stackcount t:syscalls:sys_enter_read
```

#### 4.6.6 stackcount的帮助信息

```shell
stackcount -h
```

### 4.7 trace

trace(8)是一个BCC多用途工具，可以针对多个数据源进行每个事件的跟踪，支持kprobes、uprobes、跟踪点和USDT探针。

它可以用来回答以下问题：

+ 当某个内核态/用户态函数被调用时，调用参数是什么？
+ 这个函数的返回值是什么？调用失败了吗？
+ 这个函数是如何被调用的？相应的用户态或内核态函数调用栈是什么？

因为trace(8)会对每个事件产生一行输出，因此比较适合适用于低频事件。如果是诸如网络收发包、上下文切换以及内存分配等事件，每秒可能会发生高达百万次输出，这样会造成非常显著的额外开销。一种减少开销的方式是使用一个过滤表达式，只打印感兴趣的事件。高频发生的事件，更适合使用其他在内核中直接进行汇总统计的工具，如funccount(8)、stackcount(8)和argdist(8)。

#### 4.7.1 trace的示例

以下示例通过跟踪内核函数`do_sys_open()`来展示文件打开动作，相当于trace(8)版本的opensnoop(8):

![image-20241023093452788](./images/image-20241023093452788.png)

arg2是do_sys_open()函数的第2个参数，代表打开的文件名字，其类型是char*。输出结果最后一列的标签是"-"，是提供给trace(8)的格式化字符串。

#### 4.7.2 trace的语法

trace(8)的命令行参数包括可以用来改变行为的选项，以及一个或者多个探针（probe）：

```shell
trace [option] probe [probe ...]
```

probe的语法是：

```shell
eventname(signature) (boolean filter) "format string", arguments
```

signature不是必需的，仅在特定情形下需要（参看4.7.4节）。过滤条件(filter)也非必需，支持使用布尔操作符：==、<、>和!=。format string和arguments也非必需，就算没有，trace(8)也可以为每个事件打印一行，只是不会包含定制的输出字段

eventname的语法和funccount(8)类似，不过增加了对返回值的支持。

+ `name`或者`p:name`：对内核函数`name()`进行插桩(p means probe?)
+ `r::name`：对内核函数`name()`的返回值进行插桩。
+ `lib:name` 或者 `p:lib:name`：对用户态lib库中的函数`name()`进行插桩
+ `r:lib:name`或者`p:lib:name`：对用户态lib库的函数`name()`的返回值进行插桩
+ `path:name`：对位于path路径下文件中的用户态函数`name()`进行插桩
+ `r:path:name`：对位于path路径下文件中的用户态函数`name()`的返回值进行插桩
+ `t:system:name`：对名为`system:name`的内核跟踪点进行插桩(t means tracepoint?)
+ `u:lib:name`：对lib库中名为`name`的USDT探针进行插桩
+ `*`：通配符。`-r`选项允许使用正则表达式

格式字符串基于printf()实现，支持的参数与其大体相同

总的语法和编程语言类似。如下面的trace(8)单行程序：

```shell
trace 'c:open (arg2 == 42) "%s %d", arg1, arg2'
```

等价的类C语法为（仅作说明，trace(8)并不能这样执行）：

```shell
trace 'c:open {if (arg2 == 43) {printf("%s %d\n", arg1, arg2); } }'
```

在临时的跟踪分析中经常会需要定制化打印一个事件的参数，所以trace(8)是一个可随时启动的方便工具。

#### 4.7.3 trace的单行程序

列举一些帮助消息没有的单行程序。

跟踪内核函数do_sys_open()，并打印文件名：

```shell
trace 'do_sys_open "%s", arg2'
```

跟踪内核函数do_sys_open()，并打印返回值：

```shell
trace 'r::do_sys_open "ret: %d", retval'
```

跟踪do_nanosleep()，并打印用户态调用栈：

```shell
trace -U 'do_nanosleep "mode: %d", arg2'
```

跟踪通过pam库进行身份鉴别的请求：

```shell
trace 'pam:pam_start "%s: %s", arg1, arg2'
```

#### 4.7.4 trace的结构体

BCC使用系统头文件和内核头文件来获取结构体信息。比如下面这个单行程序，它对do_nanpsleep()函数进行跟踪时，需要知道task的地址：

```shell
trace 'do_nanaosleep(struct hrtimer_sleeper *t) "task: %x", t->task'
```

hrtimer_sleeper结构在内核头文件包中(`include/linux/hrtimer.h`)，因此可以自动被BCC读取。

对于不在内核头文件包中的结构体，可以手动包含对应的头文件。比如，下述程序跟踪udpv6_sendmsg()，条件是目标端口是53（即DNS端口；当使用网络字节序时为13568）：

```shell
trace -I 'net/sock.h' 'udpv6_sendmsg(struct sock *sk) (sk->sk_dport == 13568)'
```

这里为了理解sock结构体，使用`-I`参数包含了`net/sock.h`文件。这需要系统中有完整的内核源代码才能正常工作。

目前正在开发的一项新技术可以免除内核源代码的安装——BPF类型格式(BPF Type Format,BTF)，该技术会将结构体信息内嵌到编译后的二进制文件中（参看第2章）。

#### 4.7.5 trace调试文件描述符泄漏问题

一个复杂些的例子，目标是获取没有被正常关闭的文件描述符的更多信息。在文件描述符分配（通过sock_alloc()）的调用栈中可以获得这些信息，但是还需要一种方法区分那些被正常释放（通过sock_release()）掉的和没有被释放掉的分配。下图说明了该问题：

![image-20241024091416472](./images/image-20241024091416472.png)

这里可以对sock_alloc()进行跟踪，但是这会同时记录缓冲区A、B和C的调用栈信息。而实际上，我们只需要缓冲区B——在跟踪期间没有被释放。

作者使用了一个单行程序来解决这个问题，但是该命令产生的数据还需要后续处理，单行程序的部分输出如下：
![image-20241024091710510](./images/image-20241024091710510.png)![image-20241024091720182](./images/image-20241024091720182.png)

这里对sock_alloc()的返回值进行插桩，并打印它的返回值、socket的地址以及调用栈信息（使用`-K`和`-U`选项）。它还同时跟踪了内核函数__sock_release()，获取了第2个参数：这样可以获得别关闭的socket的地址，`-t`选项会为这些事件打出时间戳。

作者对上述输出进行了截取，显示出对于地址`0xffff9c76526dac00`只有一个分配和释放的组合。对这些输出进行后处理，就可以排查到没有释放的socket。这个问题也可使用专门的、类似memleak(8)的BCC工具来解决，在第7张会介绍。该工具会将调用栈保存在BPF映射表结构中，当释放动作发生的时候，再将其从BPF映射表中伤处。这样就可以通过这个映射表打印出那些长时间未被释放的地址。

#### 4.7.6 trace的帮助信息

```shell
trace -h
```

### 4.8 argdist

argdist(8)是一个针对函数调用参数分析的多用途工具。一个实际的例子：一台Hadoop服务器遇到了TCP性能问题，已经定位到时零窗口宣告(zero-window advertisement)问题。作者使用argdist(8)单行程序对生产环境中的窗口进行统计分析。下面是问题的部分输出：

![image-20241024092933943](./images/image-20241024092933943.png)![image-20241024092942500](./images/image-20241024092942500.png)

上述工具对内核函数`__tcp_select_window()`的返回值进行插桩，并将返回值以2的幂为区间进行统计聚合(`-H`)。默认情况下，argdist(8)每秒打印一次结果。上述直方图中“0->1”行显示大小为0的窗口问题：一共发生了6100次。

#### 4.8.1 argdist的语法

argdist(8)的命令行参数设定汇总输出的类型、被插桩的事件以及要进行汇总的数据：

```shell
argdist {-C|-H} [option] probe
```

argdist(8)需要参数为`-C`或者`-H`

+ `-C`：频率统计
+ `-H`：以2的幂为区间输出直方图

probe的语法：

```shell
eventname(signature)[:type,[,type...]:expr[,expr...][:filter][#label]]
```

eventname和signature的语法和trace(8)命令几乎一样，差别在于内核函数名的缩写不可用。这里内核函数`vfs_read()`不能直接使用“vfs_read”，而需要通过"p::vfs_read"使用。signature字段是需要的，即使为空白，也需要使用空括号（"()"）。

type设定了要被展示的值的类型：无符号32位整数位u32，无符号64整数位u64，以此类推。支持多种类型，包括字符串`char*`

expr是要汇总统计的表达式。可以是一个函数或者一个跟踪点参数。还有一些特殊的变量，只能用于返回值的探测。

+ `$retval`：函数的返回值
+ `$latency`：从进入到返回的时长，单位是纳秒
+ `$entry(param)`：在探针进入(entry)时param的值

filter是可选的布尔表达式，用来对事件进行过滤。支持`==`、`!=`、`<`和`>`。

label是可选设置，用来为输出增加标签文本以达到内嵌文档的效果。

#### 4.8.2 argdist的单行程序

一些额外的示例。

将内核函数`vfs_read()`的返回值以直方图的形式打印出来：

```shell
argdist -H 'r::vfs_read()'
```

以直方图方式对PID1005的进程的用户态调用libc的read()函数的返回值(size)进行统计并输出：

```shell
argdist -p 1005 -H 'r:c:read()'
```

根据调用号(syscall ID)对系统调用进行计数，这里使用了`raw_syscall:sysenter`这个跟踪点：

```shell
argdist -C 't:raw_syscalls:sys_enter():int:args->id'
```

对tcp_sendmsg()的参数size进行统计：

```shell
argdist -C 'p::tcp_sendmsg(struct sock *sk,struct msghdr *msg,size_t size):u32:size'
```

对tcp_sendmsg()的size作为以2的幂为区间的直方图打印出来：

```shell
argdist -H 'p::tcp_sendmsg(struct sock *sk,struct msghdr *msg,size_t size):u32:size'
```

将PID为181的进程按照文件描述符对writer()调用进行计数：

```shell
argdist -p 181 -C 'p:c:write(int fd):int:fd'
```

打印延迟大于0.1毫秒的进程读操作：

```shell
argdist -C 'r::__vfs_read():u32:$PID:$latency > 100000'
```

#### 4.8.3 argdist的帮助信息

```shell
argdist -h
```

### 4.10 开发BCC工具

本书在工具开发方面侧重于bpftrace，仅将BCC作为一个现成工具的仓库。附录C中会介绍BCC工具开发。

BCC更适合创建复杂、带有各种命令行参数、完全可定制的输出和动作的工具。相比之下，bpftrace更适合用于编写单行程序，或者不接受命令行参数/单个参数，只打印文本输出。

BCC支持使用C语言编写底层BPF控制程序，然后使用Python或者其他支持的语言编写用户态组件。但是BCC的开发耗时以及代码量可能是bpftrace的10倍。

### 4.11 BCC的内部实现

BCC由以下几部分组成：

+ 一个C++前端API，用于内核态的BPF程序的编制，包括:
  - 一个预处理宏，负责将内存引用转换为bpf_probe_read()函数调用（可能也包括其变体）
+ 一个C++后端驱动：
  - 使用Clang/LLVM编译BPF程序
  - 将BPF程序装载到内核中。
  - 将BPF程序挂载到事件上。
  - 对BPF映射表进行读/写
+ 用于编写BCC工具的语言前端：Python、C++和Lua

实现如图：

![image-20241028091932587](./images/image-20241028091932587.png)

图中的BPF、Table和USDT Python对象，是它们在libbcc和libbcc_bpf库中对应实现的封装。使用Table对象与BPF映射表数据结构进行交互，映射表中的数据也可以直接从BPF对象内部获得，下面这两行代码是等价的：

```python
counts = b.get_table("counts")
counts = b["counts"]
```

USDT是Python中的一个独立的对象，因为它的行为和kprobes、uprobes、跟踪点都不一样。在初始化阶段，它必须被挂载到一个进程的ID或者路径上。和其他事件类型不同，有些USDT需要再进程映像中设定信号量来激活。应用程序使用这些信号量来决定USDT当前是否在使用中，是否需要为其准备参数，后者它是否可以作为性能优化从而被略过。

C++组件被编译为libbcc_bpf和libbcc，它们也可以被其他软件所使用（比如bpftrace）。libbcc_bpf来自Linux内核源代码，位于`tools/lib/bpf`

BCC装载一个BPF程序并开始对某个事件进行插桩的步骤如下：

+ 创建Python BPF对象，将BPF C程序传递给该BPF对象
+ 使用BCC改写器对BPF C程序进行预处理，经内存访问替换为bpf_probe_read()调用。
+ 使用Clang将BPF C程序编译为LLVM IR
+ 使用BCC codegen根据需要增加额外的LLVM IR
+ LLVM将IR编译为BPF字节码
+ 如果用到了映射表，就创建这些映射表
+ 字节码被传送到内核，并经过BPF验证器的检查
+ 事件被启用，BPF程序被挂载到事件上。
+ BCC程序通过映射表或者perf_event缓冲区读取数据。

### 4.12 BCC的调试

BCC的调试可以通过打印语句、BCC调试模式、bpflist以及重置事件等方式。其他常见问题见18章。

下图显示程序编译的流程和各个环节中可以使用的调试工具。

![image-20241029091704288](./images/image-20241029091704288.png)

#### 4.12.1 printf()调试

